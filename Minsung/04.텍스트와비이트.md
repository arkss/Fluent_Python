# 텍스트와 바이트

파이썬 3부터 인간이 사용하는 텍스트 문자열과 원시 바이트 시퀀스를 엄격히 구분하기 시작했습니다. 이번 장에서는 유니코드 문자열, 이진 시퀀스, 그리고 이 둘 간의 변환에 사용되는 인코딩에 대해서 설명을 합니다.



## 4.1 문자 문제

현재 '문자'를 가장 잘 정의한 것은 유니코드 문자입니다. 따라서 파이썬 3의 str에서 가져오는 항목도 유니코드 문자입니다.

> 파이썬 2에서 str은 유니코드가 아닌 바이트로 가져왔습니다.



코드 포인트를 바이트로 변환하는 것을 **인코딩**, 바이트를 코드 포인트로 변환하는 것을 **디코딩** 이라고 합니다. 

```python
s = 'cafè'
print(len(s)) # 4

b = s.encode('utf8')
print(b)      # b'caf\xc3\xa8'
print(len(b)) # 5
```



### 4.2 바이트에 대한 기본 지식

이진 시퀀스형은 파이썬2의 str과 여러모로 다릅니다. 

이진 시퀀스형을 위해 사용되는 내장 자료형은 `bytes`와 `bytearray` 두 가지 존재합니다.

 `bytes`와 `bytearray`에 들어있는 각 항목은 0~255 사이의 정수로 파이썬 2의 str에 들어있는 문자 하나로 구성된 문자열과는 다릅니다. 

그러나 이진 시퀀스를 슬라이싱하면 언제나 동일한 자료형의 이진 시퀀스가 만들어지며 슬라이스 길이가 1일 때도 마찬가지입니다.

아래 예시를 살펴봅시다.

``` python
cafe = bytes('cafè', encoding='utf_8')
print(cafe)
# b'caf\xc3\xa8'

print(cafe[0])  # 99
print(cafe[:1]) # b'c'

for i in range(len(cafe)):
    print(cafe[i:i+1])
"""
b'c'
b'a'
b'f'
b'\xc3'
b'\xa8'
"""
    
cafe_arr = bytearray(cafe)
print(cafe_arr)
# bytearray(b'caf\xc3\xa8')
print(cafe_arr[-1:])
# bytearray(b'\xa8')
```

* 5번째 줄 : 각 항목은 range(256)에 들어가는 정수
* 6번째 줄 : `bytes`는 슬라이싱해도 `bytes`
* 11번째 줄 : `bytearray`는 슬라이싱해도 `bytearray`

> cafe[0]과 cafe[:1]이 다르다는 점이 어색할 수도 있지만 이는 자연스러운 현상입니다.
>
> s[0] == s[:1]이 성립하는 건 str가 유일합니다.
>
> ``` python
> test = [1, 2, 3]
> 
> print(test[:1]) # [1]
> print(test[0])  # 1
> 
> ```



이진 시퀀스가 실제로 정수형의 시퀀스이기는 하지만 리터럴 표기법을 보면 실제로는 아스키 텍스트가 들어있는 경우가 많습니다. 따라서 각 바이트 값에 따라 아래 세 가지 형태로 출력됩니다.

* 화면에 출력 가능한 아스키 문자(공백에서 ~까지)는 아스키 문자 그대로 출력
* 탭, 개행 문자, 캐리지 리턴, 백슬래시(\\)는 이스캐이프 시퀀스(\\t, \\n, \\r, \\\\)로 출력
* 그 외의 값은 널 바이트를 나타내는 \\x00처럼 16진수 이스케이프 시퀀스로 출력



### 4.2.1 구조체와 메모리 뷰

`struct`모듈은 패킹된 바이트를 다양한 형의 필도로 구성된 튜플로 분석하고, 이와 반대로 튜플을 패킹된 바이트로 변환하는 함수를 제공합니다.

``` python
import struct
fmt = '<3s3sHH'

with open('test.gif', 'rb') as fp:
    img = memoryview(fp.read())

header = img[:10]
print(bytes(header))
# b'GIF89a\x00\x01\x90\x00'

print(struct.unpack(fmt, header))
# (b'GIF', b'89a', 256, 144)

del header
del img
```

* 2번째 줄 : struct의 포맷 지정 (<: 리틀엔디언, 3s: 3바이트 시퀀스 두 개, H: 16비트 정수)
* 12번째 줄 : memoryview를 (종류, 버전, 너비, 높이) 튜플로 언패킹





## 4.3 기본 인코더/디코더

텍스트를 바이트로, 바이트를 텍스트로 변환하기 위해 파이썬에서 100여 개의 **코덱**(인코더/디코더)가 포함되어 있습니다. 

```python
for codec in ['latin_1', 'utf_8', 'utf_16']:
    print(codec, 'El Niño'.encode(codec), sep='\t')

"""
latin_1 b'El Ni\xf1o'
utf_8   b'El Ni\xc3\xb1o'
utf_16  b'\xff\xfeE\x00l\x00 \x00N\x00i\x00\xf1\x00o\x00'
"""
```



ASCII나 GB2312 같은 다중바이트 인코딩도 유니코드 문자를 모두 표현할 수 없습니다. 그러나 UTF 인코딩은 모든 유니코드 코드 포인트를 처리할 수 있게 만들어졌습니다.



## 4.4 인코딩/디코딩 문제 이해하기

`UnicodeError`라는 범용 예외가 있지만 거의 항상 `UnicodeEncodeError`나 `UnicodeDecodeError`같은 구체적인 예외가 발생합니다. 또한 파이썬 모듈을 로딩할 때 소스코드가 예기치 않은 방식으로 인코딩되어 있으면 `SyntaxError`가 발생하기도 합니다.



### 4.4.1 UnicodeEncodeError 처리하기

UTF가 아닌 대부분의 코덱은 유니코드 문자의 일부만 처리할 수 있습니다. 따라서 errors인수에 별도의 처리기를 지정해주지 않으면 처리할 수 없는 문제가 있는 경우 `UnicodeEncodeError`가 발생합니다.

``` python
city = 'São Paulo'
e1 = city.encode('utf-8')

print(e1) # b'S\xc3\xa3o Paulo'

e2 = city.encode('ascii')
# UnicodeEncodeError: 'ascii' codec can't encode character '\xe3' in position 1: ordinal not in range(128)

e3 = city.encode('ascii', errors='ignore')
print(e3) # b'So Paulo'

e4 = city.encode('ascii', errors='replace')
print(e4) # b'S?o Paulo'
```



### 4.4.2 UnicodeDecodeError 처리하기

모든 바이트가 아스키 문자나  UTF문자가 될 수 없습니다. 따라서 이진 시퀀스를 텍스트로 변환할 때 적합한 문자로 변환할 수 없는 경우 `UnicodeDecodeError`가 발생합니다.

하지만 `cp1252`, `iso8859_1` 등의 레거시 8비트 코덱은 무작위 비트 배열에 대해서도 에러를 발생시키지 않고 바이트 스트림으로 디코딩합니다.

```python
octets = b'Montr\xe9al'

d1 = octets.decode('cp1252')
print(d1) # Montréal

d2 = octets.decode('utf_8')
print(d2)
"""
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte
"""

```



### 4.4.3 예상과 달리 인코딩된 모듈을 로딩할 때 발생하는 SyntaxError

```python
print('Olá Mundo!')
```

그냥 이것도 잘 되는데 언제 SyntaxError???



### 4.4.4 바이트 시퀀스의 인코딩 방식을 알아내는 방법

바이트 시퀀스의 인코딩 방법은 알아낼 수 없습니다. 따라서 반드시 별도로 인코딩 정보를 가져와야 합니다.

그렇지만 경험과 통계를 통해 인코딩 방식을 추정할 수 있습니다. 

예를 들어 b'\x00' 바이트가 많이 나타난다면, 이 파일은 8비트가 아니라 16, 32비트로 인코딩 되어 있을 가능성이 큽니다. 

일반적으로 자연어 중간에는 널 문자가 들어가지 않기 때문이죠.

그리고 b'\x20\x00' 바이트 시퀀스가 자주 나타난다면, 이 문자는 잘 사용되지 않는 U+2000(ENQUAD 문자)이라기 보다는 UTF-16LE 인코딩에서의 공백문자(U+0020)일 가능성이 큽니다.

> 예시가 이해가 안된다

### 4.4.5 BOM: 유용한 깨진 문자

>  이해가 잘 안된다. 다시 보자



## 4.5 텍스트 파일 다루기

텍스트를 처리할 때 최고의 방법은 `유니코드 샌드위치` 입니다. 

이 말의 의미는 샌드위치가 두 빵이 패티를 감싼 모습 처럼 입력과 출력 시에는 bytes를 사용하지만 패티, 즉 프로그램의 비지니스 로직에서는 str으로 사용하는 것을 말합니다.

인코딩 방식을 알아내기 위해서 파일 내용을 분석하는 경우가 아니라면 텍스트 파일을 이진 모드로 열지 않는 것이 좋습니다.



## 4.6 제대로 비교하기 위해 유니코드 정규화하기

유니코드에는 결합 문자가 있기 때문에 문자열 비교가 간단하지 않습니다. 앞 문자에 연결되는 발음 구별 기호는 인쇄할 때 앞 문자와 하나로 결합되어 출력됩니다.

예를 들어 `café`는 네 개나 다섯 개의 코드 포인트를 이용해서 두 가지 방식으로 표현할 수 있지만 결과는 동일하게 나타납니다.

```python
s1 = 'café'
s2 = 'cafe\u0301'

print(s1, s2)
# café café
print(len(s1), len(s2))
# 4 5
print(s1 == s2)
# False
```



코드 포인트 U+0301은 COMBINING ACUTE ACCENT입니다. `e` 다음에 이 문자가 오면 `é` 를 만듭니다.

유니코드 표준에서는 `é` 와 `e\u0301`을 규범적으로 동일하다고 하며, 애플리케이션에서 동일하게 처리해야합니다. 

하지만 파이썬은 서로 다른 두 개의 코드 포인트 시퀀스를 보고 동일하지 않다고 판단합니다.

이 문제를 해결하려면 `unicodedata.normalize()` 를  통해 유니코드를 정규화해야 합니다.

이 함수의 인자는 NFC, NFD, NFKC, NFKD 중 하나여야 합니다.

* NFC

  코드 포인트를 조합해서 가장 짧은 동일 문자열을 생성

  키보드는 일반적으로 결합된 문자를 입력할 수 있으므로 사용자가 입력하는 텍스트는 기본적으로 NFC

  W3C가 추천하는 정규화 형식

* NFD

  조합된 문자를 기본 문자와 별도의 결합 문자로 분리

``` python
from unicodedata import normalize

s1 = 'café'
s2 = 'cafe\u0301'

NFC_s1 = normalize('NFC', s1)
NFC_s2 = normalize('NFC', s2)
NFD_s1 = normalize('NFD', s1)
NFD_s2 = normalize('NFD', s2)

print(len(s1), len(s2))         # 4 5
print(len(NFC_s1), len(NFC_s2)) # 4 4
print(len(NFD_s1), len(NFD_s2)) # 5 5
print(NFC_s1 == NFC_s2) # True
print(NFD_s1 == NFD_s2) # True
```



K가 들어간 NFKC, NFKD은 호환성이 추가되었습니다. 

이 방식에서 각 호환성 문자는 포맷팅 손실이 발생하더라도 선호하는 형태의 하나 이상의 문자로 구성된 호환성 분할로 치환됩니다.



### 4.6.1 케이스 폴딩

본질적으로 케이스 폴딩은 모든 텍스트를 소문자로 변환하는 연산이며, 약간의 변환을 동반합니다.

latin1 문자만 담고 있는 문자열의 경우 케이스 폴딩과 파이썬 내장함수 lower의 실행 결과가 동일합니다.

하지만 마이크로 기호 `μ` 는 그리스어 소문자 뮤로 변환하는 등 차이가 존재합니다.

파이썬 3.4를 기준으로 `str.casefold()`와` str.lower()` 가 서로 다른 문자를 반환하는 코드 포인트가 116개 있습니다.



## 4.7 유니코드 텍스트 정렬하기

파이썬은 각 시퀀스 안에 들어 있는 항목들을 하나하나 비교함으로써 어떠한 자료형의 시퀀스도 정렬할 수 있습니다.

정렬 규칙은 현지 언어에 따라 달라집니다.



### 4.7.1 유니코드 대조 알고리즘을 이용한 정렬

유니코드 대조 알고리즘(UCA)을 순수 파이썬으로 구현 PyUCA가 있습니다.



## 4.8 유니코드 데이터베이스

유니코드 표준은 수많은 구조화된 텍스트 파일의 형태로 하나의 완전한 데이터베이스를 제공합니다. 이 데이터베이스는 코드 포인트를 문자명으로 매핑하는 테이블 뿐만 아니라 각 문자에 대한 메타데이터 및 문자의 연관 방법을 담고 있습니다.

`unicodedata` 모듈에는 문자 메타데이터를 반환하는 함수들이 있습니다. 

``` python
import unicodedata
import re

re_digit = re.compile(r'\d')

sample = '1\xbc\xb2\u0969\u136b\u216b\u2466\u2480\u3285'

for char in sample:
    print('U+%04x' % ord(char),
          char.center(6),
          're_dig' if re_digit.match(char) else '-',
          'isdig' if char.isdigit() else '-',
          'isnum' if char.isnumeric() else '-',
          format(unicodedata.numeric(char), '5.2f'),
          unicodedata.name(char),
          sep='\t'
          )

"""
U+0031    1     re_dig  isdig   isnum    1.00   DIGIT ONE
U+00bc    ¼     -       -       isnum    0.25   VULGAR FRACTION ONE QUARTER
U+00b2    ²     -       isdig   isnum    2.00   SUPERSCRIPT TWO
U+0969    ३     re_dig  isdig   isnum    3.00   DEVANAGARI DIGIT THREE
U+136b    ፫     -       isdig   isnum    3.00   ETHIOPIC DIGIT THREE
U+216b    Ⅻ     -       -       isnum   12.00   ROMAN NUMERAL TWELVE
U+2466    ⑦     -       isdig   isnum    7.00   CIRCLED DIGIT SEVEN
U+2480    ⒀     -       -       isnum   13.00   PARENTHESIZED NUMBER THIRTEEN
U+3285    ㊅    -       -       isnum    6.00   CIRCLED IDEOGRAPH SIX
"""
```

결과를 보면 정규표현식 r'\d'가 isdigit() 함수가 숫자로 인식하는 문자 중 일부를 숫자가 아니라고 판단합니다. 이처럼 re 모듈은 유지코드를 잘 인식하지 못해 PyPI를 통해 새로 제공되는 regex 모듈은 re 모듈을 대체하기 위해 만들어졌으며 유니코드를 더욱 잘 지원합니다.





## 4.9 이중 모드 str 및 bytes API

표준 라이브러리에는 str이나 bytes 인수를 모두 받으며, 인수의 자료형에 따라 다르게 작동하는 함수들이 있습니다.

대표적으로 `re`와 `os` 이 있습니다.



### 4.9.1 정규 표현식에서의 str와 bytes

bytes로 정규표현식을 만들면 \d와 \w 같은 패턴은 아스키 문자만 매칭되지만, str로 이 패턴을 만들면 아스키 문자 이외에 유니코드 숫자나 문자도 매칭됩니다. 



### 4.9.2 os 모듈 함수에서 str과 bytes

GNU/리눅스 커널은 유니코드를 모릅니다. 따라서 실제 OS의 파일명은 어떠한 인코딩 체계에서도 올바르지 않은 바이트 시퀀스로 구성되어 있으며 str로 디코딩 할 수 없습니다.

이 문제를 해결하기 위해 파일명이나 경로명을 받는 모든 os 모듈 함수는 str이나 bytes 형의 인수를 받습니다. 

이런 함수를 str인수로 호출하면 인수는 sys.getfilesystemencoding()함수에 의해 지정된 코덱을 이용해서 자동으로 변환되고, 운영 체계의 응답은 동일 코덱을 이용해서 디코딩됩니다. 대부분의 경우 이 방법은 유니코드 샌드위치 모델에 따라 원하는대로 작동합니다.

하지만 처리할 수 없는 파일명을 다루거나 수정해야 할 때는 bytes인수를 os함수에 전달해서 bytes 변환값을 가져올 수 있습니다. 